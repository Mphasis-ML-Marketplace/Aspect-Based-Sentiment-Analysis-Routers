{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect Based Sentiment Analysis: Routers\n",
    "\n",
    "\n",
    "### This is a Natural Language Processing based solution which can detect up to 9 aspects and their respective sentiments from online product reviews for Routers.\n",
    "\n",
    "This sample notebook shows you how to deploy Aspect Based Sentiment Analysis: Routers using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to Aspect Based Sentiment Analysis: Routers. If so, skip step: [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Visualize output](#D.-Visualize-output)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "3. [Perform batch inference](#3.-Perform-batch-inference) \n",
    "4. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page Product Review Aspect Based Sentiment Analysis: Routers. \n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn='arn:aws:sagemaker:us-east-2:786796469737:model-package/router-absa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json \n",
    "import uuid\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "from IPython.display import Image\n",
    "from PIL import Image as ImageEdit\n",
    "import urllib.request\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-2-786796469737'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "bucket=sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='router-absa'\n",
    "\n",
    "content_type='text/plain'\n",
    "\n",
    "real_time_inference_instance_type='ml.m5.large'\n",
    "batch_transform_inference_instance_type='ml.m5.large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.predictor.Predictor(endpoint, session,content_type)\n",
    "\n",
    "#create a deployable model from the model package.\n",
    "model = ModelPackage(role=role,\n",
    "                    model_package_arn=model_package_arn,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    predictor_cls=predict_wrapper)\n",
    "\n",
    "#Deploy the model\n",
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'input/sample.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Add code snippet that shows the payload contents>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"ContentType\": \"application/json\",\r\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint \\\n",
    "    --endpoint-name $model_name \\\n",
    "    --body fileb://$file_name \\\n",
    "    --content-type $content_type \\\n",
    "    --region $sagemaker_session.boto_region_name \\\n",
    "    output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"review\": \"Installation was pretty straight forward. What is nice about the way this dishwasher is configured is that the hot water connection can be accessed from the front of the machine if you remove the kick plate. So if I had to retighten the water connection or something I wouldn't have to drag the machine out from under the counter.\\r\\nThe instructions could have been written clearer, especially regarding the leveling feet. Heads up to first time dishwasher installers: It only comes with a drain hose. You have to supply the water connections/adapters as well as any appliance electrical plug (If you are not hard wiring it).\\r\\n\\r\\nIt's quiet. It cleans and dries very well. It looks very nice too. However, the baskets are designed for Western dishes and cookware and some Indian dishes, such as stainless steel plates with high sides don't fit easily in the baskets.\",\n",
      " \"topics\": [\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Easy to Install\": 0.8775739832058218\n",
      "   },\n",
      "   \"sentence\": \"instal pretti straight forward\",\n",
      "   \"sentiment\": {\n",
      "    \"Easy to Install\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Aesthetic\": 0.45787882015618125,\n",
      "    \"Connectivity\": 0.12442965101777582,\n",
      "    \"Security\": 0.16150378647119004\n",
      "   },\n",
      "   \"sentence\": \"nice way dishwash configur hot water connect access machin remov kick plate\",\n",
      "   \"sentiment\": {\n",
      "    \"Aesthetic\": \"positive\",\n",
      "    \"Connectivity\": \"positive\",\n",
      "    \"Security\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Accessibility\": 0.33443867213350165,\n",
      "    \"Aesthetic\": 0.1853215660572112,\n",
      "    \"Connectivity\": 0.15951385536821455\n",
      "   },\n",
      "   \"sentence\": \"retighten water connect wouldn t drag machin counter\",\n",
      "   \"sentiment\": {\n",
      "    \"Accessibility\": \"positive\",\n",
      "    \"Aesthetic\": \"positive\",\n",
      "    \"Connectivity\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Easy to Install\": 0.20105345520046242,\n",
      "    \"Range\": 0.7090865829635573\n",
      "   },\n",
      "   \"sentence\": \"instruct written clearer especi level feet\",\n",
      "   \"sentiment\": {\n",
      "    \"Easy to Install\": \"positive\",\n",
      "    \"Range\": \"neutral\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Accessibility\": 0.16000505613581728,\n",
      "    \"Aesthetic\": 0.49900827895275734,\n",
      "    \"Easy to Install\": 0.17613233153537722\n",
      "   },\n",
      "   \"sentence\": \"head time dishwash instal come drain hose\",\n",
      "   \"sentiment\": {\n",
      "    \"Accessibility\": \"negative\",\n",
      "    \"Aesthetic\": \"negative\",\n",
      "    \"Easy to Install\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Price\": 0.8670188097567942\n",
      "   },\n",
      "   \"sentence\": \"suppli water connections/adapt applianc electr plug hard wire\",\n",
      "   \"sentiment\": {\n",
      "    \"Price\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Aesthetic\": 0.9334345598087684\n",
      "   },\n",
      "   \"sentence\": \"s quiet\",\n",
      "   \"sentiment\": {\n",
      "    \"Aesthetic\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Aesthetic\": 0.2197732379934666,\n",
      "    \"Connectivity\": 0.4896327999506472,\n",
      "    \"Easy to Install\": 0.28292042688451\n",
      "   },\n",
      "   \"sentence\": \"clean dri\",\n",
      "   \"sentiment\": {\n",
      "    \"Aesthetic\": \"positive\",\n",
      "    \"Connectivity\": \"positive\",\n",
      "    \"Easy to Install\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Aesthetic\": 0.687571976306027,\n",
      "    \"Price\": 0.2693704267150329\n",
      "   },\n",
      "   \"sentence\": \"look nice\",\n",
      "   \"sentiment\": {\n",
      "    \"Aesthetic\": \"positive\",\n",
      "    \"Price\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Aesthetic\": 0.45258517856754704,\n",
      "    \"Price\": 0.15984259859533353,\n",
      "    \"Range\": 0.26412142756218077\n",
      "   },\n",
      "   \"sentence\": \"basket design western dish cookwar indian dish stainless steel plate high side t fit easili basket\",\n",
      "   \"sentiment\": {\n",
      "    \"Aesthetic\": \"negative\",\n",
      "    \"Price\": \"negative\",\n",
      "    \"Range\": \"negative\"\n",
      "   }\n",
      "  }\n",
      " ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('output.txt', 'r') as f:\n",
    "    output = json.load(f)\n",
    "print(json.dumps(output, indent = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=sage.predictor.Predictor(model_name, sagemaker_session,content_type)\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together. If you are not familiar with batch transform, and want to learn more, see these links:\n",
    "1. [How it works](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html)\n",
    "2. [How to run a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-786796469737/router-absa\n"
     ]
    }
   ],
   "source": [
    "#upload the batch-transform job input files to S3\n",
    "transform_input_folder = \"input\"\n",
    "transform_input = sagemaker_session.upload_data(transform_input_folder, key_prefix=model_name) \n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\u001b[32m2022-02-04T11:37:09.553:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.20.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.276753: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.277145: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.277378: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (506f9bd7017f): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.277858: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.306844: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.307381: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcc9c000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.307623: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.20.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.276753: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.277145: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.277378: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (506f9bd7017f): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.277858: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.306844: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.307381: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcc9c000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.307623: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.310613: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 93763584 exceeds 10% of free system memory.\n",
      " * Serving Flask app 'serve' (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://169.254.255.131:8080/ (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Feb/2022 11:37:09] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Feb/2022 11:37:09] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.310613: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 93763584 exceeds 10% of free system memory.\n",
      " * Serving Flask app 'serve' (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://169.254.255.131:8080/ (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Feb/2022 11:37:09] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Feb/2022 11:37:09] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:33.435768: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 131632128 exceeds 10% of free system memory.\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:33.499868: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 131632128 exceeds 10% of free system memory.\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:33.435768: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 131632128 exceeds 10% of free system memory.\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:33.499868: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 131632128 exceeds 10% of free system memory.\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Feb/2022 11:37:33] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Feb/2022 11:37:33] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\n",
      "\u001b[32m2022-02-04T11:37:09.553:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.20.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.276753: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.277145: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.277378: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (506f9bd7017f): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.277858: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.306844: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.307381: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcc9c000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.307623: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.20.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.276753: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.277145: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.277378: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (506f9bd7017f): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.277858: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.306844: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.307381: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcc9c000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.307623: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:06.310613: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 93763584 exceeds 10% of free system memory.\n",
      " * Serving Flask app 'serve' (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://169.254.255.131:8080/ (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Feb/2022 11:37:09] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Feb/2022 11:37:09] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:06.310613: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 93763584 exceeds 10% of free system memory.\n",
      " * Serving Flask app 'serve' (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://169.254.255.131:8080/ (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Feb/2022 11:37:09] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Feb/2022 11:37:09] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Feb/2022 11:37:18] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Feb/2022 11:37:18] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:33.424392: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33067008 exceeds 10% of free system memory.\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:33.430107: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33067008 exceeds 10% of free system memory.\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:33.435768: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 131632128 exceeds 10% of free system memory.\u001b[0m\n",
      "\u001b[34m2022-02-04 11:37:33.499868: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 131632128 exceeds 10% of free system memory.\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:33.424392: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33067008 exceeds 10% of free system memory.\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:33.430107: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33067008 exceeds 10% of free system memory.\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:33.435768: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 131632128 exceeds 10% of free system memory.\u001b[0m\n",
      "\u001b[35m2022-02-04 11:37:33.499868: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 131632128 exceeds 10% of free system memory.\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Feb/2022 11:37:33] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m169.254.255.130 - - [04/Feb/2022 11:37:33] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Run the batch-transform job\n",
    "transformer = model.transformer(1, batch_transform_inference_instance_type)\n",
    "transformer.transform(transform_input, content_type=content_type)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file loaded from bucket\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "s3_conn = boto3.client(\"s3\")\n",
    "with open('output2.txt', 'wb') as f:\n",
    "    s3_conn.download_fileobj(bucket, os.path.basename(transformer.output_path)+'/sample.txt.out', f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"review\": \"Installation was pretty straight forward. What is nice about the way this dishwasher is configured is that the hot water connection can be accessed from the front of the machine if you remove the kick plate. So if I had to retighten the water connection or something I wouldn't have to drag the machine out from under the counter.\\r\\nThe instructions could have been written clearer, especially regarding the leveling feet. Heads up to first time dishwasher installers: It only comes with a drain hose. You have to supply the water connections/adapters as well as any appliance electrical plug (If you are not hard wiring it).\\r\\n\\r\\nIt's quiet. It cleans and dries very well. It looks very nice too. However, the baskets are designed for Western dishes and cookware and some Indian dishes, such as stainless steel plates with high sides don't fit easily in the baskets.\",\n",
      " \"topics\": [\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Easy to Install\": 0.8775739832058218\n",
      "   },\n",
      "   \"sentence\": \"instal pretti straight forward\",\n",
      "   \"sentiment\": {\n",
      "    \"Easy to Install\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Aesthetic\": 0.45787882015618125,\n",
      "    \"Connectivity\": 0.12442965101777582,\n",
      "    \"Security\": 0.16150378647119004\n",
      "   },\n",
      "   \"sentence\": \"nice way dishwash configur hot water connect access machin remov kick plate\",\n",
      "   \"sentiment\": {\n",
      "    \"Aesthetic\": \"positive\",\n",
      "    \"Connectivity\": \"positive\",\n",
      "    \"Security\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Accessibility\": 0.33443867213350165,\n",
      "    \"Aesthetic\": 0.1853215660572112,\n",
      "    \"Connectivity\": 0.15951385536821455\n",
      "   },\n",
      "   \"sentence\": \"retighten water connect wouldn t drag machin counter\",\n",
      "   \"sentiment\": {\n",
      "    \"Accessibility\": \"positive\",\n",
      "    \"Aesthetic\": \"positive\",\n",
      "    \"Connectivity\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Easy to Install\": 0.20105345520046242,\n",
      "    \"Range\": 0.7090865829635573\n",
      "   },\n",
      "   \"sentence\": \"instruct written clearer especi level feet\",\n",
      "   \"sentiment\": {\n",
      "    \"Easy to Install\": \"positive\",\n",
      "    \"Range\": \"neutral\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Accessibility\": 0.16000505613581728,\n",
      "    \"Aesthetic\": 0.49900827895275734,\n",
      "    \"Easy to Install\": 0.17613233153537722\n",
      "   },\n",
      "   \"sentence\": \"head time dishwash instal come drain hose\",\n",
      "   \"sentiment\": {\n",
      "    \"Accessibility\": \"negative\",\n",
      "    \"Aesthetic\": \"negative\",\n",
      "    \"Easy to Install\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Price\": 0.8670188097567942\n",
      "   },\n",
      "   \"sentence\": \"suppli water connections/adapt applianc electr plug hard wire\",\n",
      "   \"sentiment\": {\n",
      "    \"Price\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Aesthetic\": 0.9334345598087684\n",
      "   },\n",
      "   \"sentence\": \"s quiet\",\n",
      "   \"sentiment\": {\n",
      "    \"Aesthetic\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Aesthetic\": 0.2197732379934666,\n",
      "    \"Connectivity\": 0.4896327999506472,\n",
      "    \"Easy to Install\": 0.28292042688451\n",
      "   },\n",
      "   \"sentence\": \"clean dri\",\n",
      "   \"sentiment\": {\n",
      "    \"Aesthetic\": \"positive\",\n",
      "    \"Connectivity\": \"positive\",\n",
      "    \"Easy to Install\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Aesthetic\": 0.687571976306027,\n",
      "    \"Price\": 0.2693704267150329\n",
      "   },\n",
      "   \"sentence\": \"look nice\",\n",
      "   \"sentiment\": {\n",
      "    \"Aesthetic\": \"positive\",\n",
      "    \"Price\": \"positive\"\n",
      "   }\n",
      "  },\n",
      "  {\n",
      "   \"aspect\": {\n",
      "    \"Aesthetic\": 0.45258517856754704,\n",
      "    \"Price\": 0.15984259859533353,\n",
      "    \"Range\": 0.26412142756218077\n",
      "   },\n",
      "   \"sentence\": \"basket design western dish cookwar indian dish stainless steel plate high side t fit easili basket\",\n",
      "   \"sentiment\": {\n",
      "    \"Aesthetic\": \"negative\",\n",
      "    \"Price\": \"negative\",\n",
      "    \"Range\": \"negative\"\n",
      "   }\n",
      "  }\n",
      " ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('output2.txt', 'r') as f:\n",
    "    output = json.load(f)\n",
    "print(json.dumps(output, indent = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
